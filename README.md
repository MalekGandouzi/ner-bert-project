# ğŸ§  Reconnaissance dâ€™EntitÃ©s NommÃ©es (NER) avec BERT

Ce projet rÃ©alise un systÃ¨me de **Reconnaissance dâ€™EntitÃ©s NommÃ©es (Named Entity Recognition â€“ NER)** en utilisant le modÃ¨le **BERT** via un **fine-tuning pour la classification de tokens**.
Il permet dâ€™identifier automatiquement certaines entitÃ©s nommÃ©es dans un texte en franÃ§ais Ã  lâ€™aide dâ€™un modÃ¨le entraÃ®nÃ©, et de les visualiser via une **interface web interactive dÃ©veloppÃ©e avec Streamlit**.

Projet rÃ©alisÃ© dans un cadre **acadÃ©mique** Ã  **Polytech Monastir** (annÃ©e universitaire 2025â€“2026).

---

## ğŸ¯ Objectif du projet

Lâ€™objectif principal est de :

* Mettre en Å“uvre un pipeline complet de **fine-tuning de BERT pour la tÃ¢che NER**
* EntraÃ®ner le modÃ¨le sur un dataset annotÃ© au format CoNLL
* Ã‰valuer les performances Ã  lâ€™aide des mÃ©triques classiques (precision, recall, F1-score)
* DÃ©ployer une **interface graphique simple et moderne** pour tester le modÃ¨le sur des textes libres

---

## ğŸ—‚ï¸ Structure du projet

```
ner-bert-project/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                # Jeux de donnÃ©es (train / valid au format CoNLL)
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ train_simple.py     # Script d'entraÃ®nement du modÃ¨le BERT NER
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ner_improved/       # ModÃ¨le entraÃ®nÃ© sauvegardÃ©
â”‚
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ load_data.py        # Chargement et prÃ©paration des donnÃ©es
â”‚
â”œâ”€â”€ app.py                  # Interface Streamlit
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â””â”€â”€ README.md
```

---

## âš™ï¸ Technologies utilisÃ©es

* **Python 3**
* **PyTorch**
* **Hugging Face Transformers**
* **SeqEval** (Ã©valuation NER)
* **Streamlit** (interface graphique)

---

## ğŸš€ Installation

1ï¸âƒ£ CrÃ©er et activer un environnement virtuel :

```bash
python -m venv venv
venv\Scripts\activate
```

2ï¸âƒ£ Installer les dÃ©pendances :

```bash
pip install -r requirements.txt
```

---

## ğŸ§  EntraÃ®nement du modÃ¨le

Lâ€™entraÃ®nement du modÃ¨le se fait via le script suivant :

```bash
python model/train_simple.py
```

Ce script :

* Charge les donnÃ©es annotÃ©es
* Tokenise les textes avec BERT
* EntraÃ®ne un modÃ¨le `BertForTokenClassification`
* Ã‰value le modÃ¨le Ã  chaque Ã©poque
* Sauvegarde le modÃ¨le final

---

## ğŸ¨ Interface graphique (Streamlit)

Une interface web permet de tester le modÃ¨le sur des textes personnalisÃ©s.

### Lancer lâ€™interface :

```bash
streamlit run app.py
```

### FonctionnalitÃ©s :

* Saisie libre de texte en franÃ§ais
* PrÃ©diction des entitÃ©s nommÃ©es
* Mise en Ã©vidence visuelle des entitÃ©s dÃ©tectÃ©es

---

## ğŸ“¸ AperÃ§u de lâ€™interface

![Interface Streamlit](assets/streamlit.png)

---

## ğŸ“Š RÃ©sultats

Le modÃ¨le montre une **amÃ©lioration progressive des performances** au cours de lâ€™entraÃ®nement, avec une diminution de la loss et une augmentation du score F1 sur le jeu de validation.
Les rÃ©sultats restent dÃ©pendants de la taille et de la qualitÃ© du dataset utilisÃ©.

---

## ğŸ‘©â€ğŸ“ğŸ‘¨â€ğŸ“ Contexte acadÃ©mique

* **Ã‰tablissement** : Polytech Monastir
* **FiliÃ¨re** : Data Science & Intelligence Artificielle
* **Niveau** : 4áµ‰ annÃ©e
* **AnnÃ©e universitaire** : 2025â€“2026

---

## âœï¸ Auteur

**Malek Gandouzi**
Ã‰tudiant en Data Science & Intelligence Artificielle

---

## ğŸ“Œ Remarque

Ce projet a Ã©tÃ© rÃ©alisÃ© Ã  des fins **pÃ©dagogiques et expÃ©rimentales** afin de se familiariser avec :

* le fine-tuning de modÃ¨les de langage,
* la tÃ¢che NER,
* et le dÃ©ploiement dâ€™un modÃ¨le via une interface simple.
